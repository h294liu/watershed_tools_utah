{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate HRU at different complexity levels ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt \n",
    "sys.path.append('../')\n",
    "import functions.geospatial_analysis as ga\n",
    "import functions.utils as ut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common paths\n",
    "control_file    = '../control_Utah.txt'\n",
    "basin_data_path = ut.read_from_control(control_file, 'basin_data_path')\n",
    "basin_name      = ut.read_from_control(control_file, 'basin_name')\n",
    "gis_path  = os.path.join(basin_data_path, 'gis/')\n",
    "\n",
    "main_path       = ut.read_from_control(control_file, 'main_path')\n",
    "results_path    = os.path.join(basin_data_path, 'results/')\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basin data files and fields\n",
    "basin_gru_shp             = ut.read_from_control(control_file, 'basin_gru_shp')  \n",
    "basin_gru_raster          = ut.set_filename(control_file, 'basin_gru_raster')\n",
    "basin_gruNo_gruId_txt     = ut.set_filename(control_file, 'basin_gruNo_gruId_txt')\n",
    "basin_dem_raster          = ut.set_filename(control_file, 'basin_dem_raster')  \n",
    "basin_slope_raster        = ut.set_filename(control_file, 'basin_slope_raster')  \n",
    "basin_aspect_raster       = ut.set_filename(control_file, 'basin_aspect_raster')\n",
    "basin_soiltype_raster     = ut.set_filename(control_file, 'basin_soiltype_raster')\n",
    "basin_radiation_raster    = ut.set_filename(control_file, 'basin_radiation_raster')\n",
    "refraster                 = ut.set_filename(control_file, 'refraster')\n",
    "basin_canopy_class_raster = ut.set_filename(control_file, 'basin_canopy_class_raster')\n",
    "basin_landcover_resample_raster  = ut.set_filename(control_file, 'basin_landcover_resample_raster')\n",
    "\n",
    "# derived filenames\n",
    "basin_gru_prj_shp     = os.path.join(gis_path, os.path.basename(basin_gru_shp).split('.shp')[0]+'_prj.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gru fieldnames\n",
    "gruNo_fieldname           = ut.read_from_control(control_file, 'gruNo_fieldname')\n",
    "gruNo_field_dtype         = ut.read_from_control(control_file, 'gruNo_field_dtype')\n",
    "gruId_fieldname           = ut.read_from_control(control_file, 'gruId_fieldname')\n",
    "\n",
    "# hru field names\n",
    "hruNo_fieldname           = ut.read_from_control(control_file, 'hruNo_fieldname')\n",
    "hruNo_field_dtype         = ut.read_from_control(control_file, 'hruNo_field_dtype')         # used to save hruNo raster (cannot be int64)\n",
    "hruId_fieldname           = ut.read_from_control(control_file, 'hruId_fieldname')           # field name of hru name, e.g., 10080012010101, 100800120102. \n",
    "    \n",
    "elev_class_fieldname      = ut.read_from_control(control_file, 'elev_class_fieldname')      # field name of the elevation class column in HRU. \n",
    "land_class_fieldname      = ut.read_from_control(control_file, 'land_class_fieldname')      # field name of the land class column in HRU. \n",
    "radiation_class_fieldname = ut.read_from_control(control_file, 'radiation_class_fieldname') # field name of the radiation class column in HRU. \n",
    "hru_area_fieldname        = ut.read_from_control(control_file, 'hru_area_fieldname')        # field name of the HRU area.\n",
    "\n",
    "hru_threshold_type        = ut.read_from_control(control_file, 'hru_threshold_type')        # use a fraction or area value to eliminate small HRUs.\n",
    "hru_threshold             = float(ut.read_from_control(control_file, 'hru_threshold'))      # if hru_thld_type = 'fraction', hru_thld = partial of the gru area.                                                                                   ## if hru_thld_type = 'value', hru_thld = elimination area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basename for dem and radiation classification in a hru level.\n",
    "dem_class_basename = 'dem_class' # basename for DEM class files (eg, 0:low elevation. 1: high elevation).\n",
    "dem_value_basename = 'dem_value' # basename for DEM value files (eg, average DEM per class).\n",
    "\n",
    "rad_class_basename = 'rad_class' # basename for radiation class files (eg, 0:low. 1:high).\n",
    "rad_value_basename = 'rad_value' # basename for radiation value files (eg, average radiation per class)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define HRU complexity levels ####\n",
    "level 0: GRU = HRU. <br>\n",
    "level 1a: use only elevation bands in HRU generation.<br>\n",
    "level 1b: use only canopy class in HRU generation.<br>\n",
    "level 1c: use only radiation class in HRU generation.<br>\n",
    "level 2a: use elevation bands and canopy class in HRU generation.<br>\n",
    "level 2b: use elevation bands and radiation class in HRU generation.<br>\n",
    "level 2c: use canopy class and radiation class in HRU generation.<br>\n",
    "level 3: use elevation bands, radiation class, canopy class in HRU generation.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_list = ['0','1a','1b','1c','2a','2b','2c','3']\n",
    "# level_list = ['2b','2c','3']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Discretize HRU ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Complexity level 0 ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:00<00:00, 644.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 0 hrus out of original 230\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev0_simplified.shp\n",
      "\n",
      "--- Complexity level 1a ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:00<00:00, 634.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 0 hrus out of original 439\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev1a_simplified.shp\n",
      "\n",
      "--- Complexity level 1b ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:01<00:00, 118.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 44 hrus out of original 342\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev1b_simplified.shp\n",
      "\n",
      "--- Complexity level 1c ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:00<00:00, 621.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 0 hrus out of original 446\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev1c_simplified.shp\n",
      "\n",
      "--- Complexity level 2a ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:06<00:00, 37.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 91 hrus out of original 617\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev2a_simplified.shp\n",
      "\n",
      "--- Complexity level 2b ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:00<00:00, 592.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 0 hrus out of original 861\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev2b_simplified.shp\n",
      "\n",
      "--- Complexity level 2c ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [00:51<00:00,  4.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 120 hrus out of original 650\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev2c_simplified.shp\n",
      "\n",
      "--- Complexity level 3 ---\n",
      "  classifying input rasters\n",
      "  defining new HRUs\n",
      "  adding HRU areas to shapefile\n",
      "  simplify shapefile by eliminating small HRUs with their neighbors\n",
      "    reading hru shapefile\n",
      "    buffering topology\n",
      "    eliminating ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 230/230 [01:16<00:00,  3.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      -- info: no neighbors found for 0 hrus, used dominant gru type instead\n",
      "    updating hruIds, hru numbers and datatypes\n",
      "    done: eliminated 228 hrus out of original 1174\n",
      "  wrote shapefile /Users/hongliliu/Documents/tmp/utah/results/hru_lev3_simplified.shp\n"
     ]
    }
   ],
   "source": [
    "for level in level_list:\n",
    "\n",
    "    print('\\n--- Complexity level %s ---' %(level))\n",
    "    \n",
    "    #  --- PART 1. define output files of discretization--- \n",
    "    hru_str         = 'hru_lev' + str(level)\n",
    "    hru_str_simp    = hru_str + '_simplified'     \n",
    "    \n",
    "    hru_raster      = os.path.join(results_path, hru_str+'.tif')       # original HRU\n",
    "    hru_vector      = os.path.join(results_path, hru_str+'.shp')\n",
    "    hru_raster_simp = os.path.join(results_path, hru_str_simp+'.tif')  # simplified HRU\n",
    "    hru_vector_simp = os.path.join(results_path, hru_str_simp+'.shp')    \n",
    "\n",
    "    # these settings should be in control file\n",
    "    dem_classif_trigger = 300 # Elvation difference value per GRU used to trigger elevation classification.\n",
    "    dem_bins            = 'median' # Elevation classification method. 'median' means using the median value per GRU as the classification threhold.\n",
    "    # dem_bins            = [1750, 3000, 3500]\n",
    "    dem_class_raster    = os.path.join(results_path, dem_class_basename+'_lev'+str(level)+'.tif')\n",
    "    dem_value_raster    = os.path.join(results_path, dem_value_basename+'_lev'+str(level)+'.tif')\n",
    "      \n",
    "    rad_classif_trigger = 50 # None # Radiation difference value per GRU used to trigger elevation classification.\n",
    "    rad_bins            = 'median' # Radiation classification method. 'median' means using the median value per GRU as the classification threhold.\n",
    "    rad_class_raster    = os.path.join(results_path, rad_class_basename+'_lev'+str(level)+'.tif')\n",
    "    rad_value_raster    = os.path.join(results_path, rad_value_basename+'_lev'+str(level)+'.tif')\n",
    "    \n",
    "    #  --- PART 2. define inputs of discretization ---\n",
    "    #   raster_list: a list of raster inputs that are used to define HRU.\n",
    "    #   fieldname_list: a list of field names corresponding to raster_list.\n",
    "    #   note:  elevation and radiation class rasters may need generation at each step, while\n",
    "    #          the landcover/canopy class raster already exists from prepare_landcover script\n",
    "\n",
    "    print('  classifying input rasters')\n",
    "\n",
    "    # level 0: GRU = HRU (benchmark). \n",
    "    if level == '0': \n",
    "        # (1) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster]\n",
    "        fieldname_list = [gruNo_fieldname]  \n",
    "\n",
    "    # level 1a: use only elevation bands in HRU generation.\n",
    "    if level == '1a': \n",
    "        # (1) classify elevation raster per gru        \n",
    "        ga.classify_raster(basin_dem_raster, basin_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                               dem_class_raster, dem_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, dem_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, elev_class_fieldname]\n",
    "    \n",
    "    # level 1b: use only canopy classes in HRU generation.\n",
    "    if level == '1b': \n",
    "        # (1) canopy class raster already exists from prepare_landcover script\n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, basin_canopy_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, land_class_fieldname]\n",
    " \n",
    "    # level 1c: use only radiation class in HRU generation.\n",
    "    if level == '1c': \n",
    "        # (1) classify radiation raster per gru\n",
    "        ga.classify_raster(basin_radiation_raster, basin_gru_raster, rad_classif_trigger, rad_bins, \n",
    "                               rad_class_raster, rad_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, rad_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, radiation_class_fieldname]\n",
    " \n",
    "    # level 2a: use elevation bands and landcover classes in HRU generation.\n",
    "    elif level == '2a': \n",
    "        # (1) classify elevation raster per gru (landcover class already exists)\n",
    "        ga.classify_raster(basin_dem_raster, basin_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                               dem_class_raster, dem_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, dem_class_raster, basin_canopy_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, elev_class_fieldname, land_class_fieldname]\n",
    "\n",
    "    # level 2b: use elevation bands and radiation class in HRU generation.\n",
    "    elif level == '2b': \n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(basin_dem_raster, basin_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                               dem_class_raster, dem_value_raster)        \n",
    "        # classify radiation raster per gru\n",
    "        ga.classify_raster(basin_radiation_raster, basin_gru_raster, rad_classif_trigger, rad_bins, \n",
    "                               rad_class_raster, rad_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, dem_class_raster, rad_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, elev_class_fieldname, radiation_class_fieldname]\n",
    "    \n",
    "    # level 2c: use landcover class and radiation class in HRU generation.\n",
    "    elif level == '2c': \n",
    "        # (1) classify radiation raster per gru (landcover class already exists)\n",
    "        ga.classify_raster(basin_radiation_raster, basin_gru_raster, rad_classif_trigger, rad_bins, \n",
    "                               rad_class_raster, rad_value_raster)        \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, basin_canopy_class_raster, rad_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, land_class_fieldname, radiation_class_fieldname]\n",
    "    \n",
    "    # level 3: use elevation bands, radiation bands, landcover classes in HRU generation.\n",
    "    elif level == '3':\n",
    "        # (1) classify elevation raster per gru\n",
    "        ga.classify_raster(basin_dem_raster, basin_gru_raster, dem_classif_trigger, dem_bins,\n",
    "                               dem_class_raster, dem_value_raster)        \n",
    "        #     classify radiation raster per gru       \n",
    "        ga.classify_raster(basin_radiation_raster, basin_gru_raster, rad_classif_trigger, rad_bins, \n",
    "                               rad_class_raster, rad_value_raster)              \n",
    "        # (2) define input files for hru discretization\n",
    "        raster_list    = [basin_gru_raster, dem_class_raster, rad_class_raster, basin_canopy_class_raster]\n",
    "        fieldname_list = [gruNo_fieldname, elev_class_fieldname, radiation_class_fieldname, land_class_fieldname]\n",
    "\n",
    "    # --- PART 3. generate HRU based on raster_list ---\n",
    "    print('  defining new HRUs')\n",
    "    # hruNo_field_dtype = 'int' # manually added\n",
    "    ga.define_hru(raster_list, fieldname_list, basin_gru_raster, basin_gruNo_gruId_txt, gruNo_fieldname, gruId_fieldname,\n",
    "                  hru_raster, hru_vector, hruNo_fieldname, hruNo_field_dtype, hruId_fieldname)\n",
    "\n",
    "    # --- PART 4. calculate HRU area ---\n",
    "    print('  adding HRU areas to shapefile')\n",
    "    in_gpd                     = gpd.read_file(hru_vector)\n",
    "    in_gpd[hru_area_fieldname] = in_gpd.area\n",
    "    in_gpd.to_file(hru_vector)\n",
    "\n",
    "    # --- PART 5. eliminate small area HRUs ---\n",
    "    # method 1: change HRU attribute to the most dominant HRU within the GRU. Use function ga.eliminate_small_hrus_dominant\n",
    "    # method 2: change HRU attribute to its largest neighbor's HRU\n",
    "    print('  simplify shapefile by eliminating small HRUs with their neighbors')\n",
    "    \n",
    "    ga.eliminate_small_hrus_neighbor(hru_vector, hru_threshold_type, hru_threshold, gruNo_fieldname, gruId_fieldname, \n",
    "                                     hruNo_fieldname, hruNo_field_dtype, hruId_fieldname, hru_area_fieldname, \n",
    "                                     fieldname_list, refraster, hru_vector_simp, hru_raster_simp)\n",
    "    print('  wrote shapefile', hru_vector_simp)\n",
    "    \n",
    "    #ga.plot_vector(hru_vector_simp, hruName_field) # quick plot for check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Calculate HRU zonal statistics ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_list = ['0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 0 ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n",
      "--- Complexity level 1a ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n",
      "--- Complexity level 1b ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n",
      "--- Complexity level 1c ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongliliu/venvs/discretize/lib/python3.9/site-packages/pyogrio/raw.py:709: RuntimeWarning: GPKG: bad application_id=0x00000000 on '/Users/hongliliu/Documents/tmp/utah/results/hru_lev1c_simplified.gpkg'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n",
      "--- Complexity level 2a ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n",
      "--- Complexity level 2b ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n",
      "--- Complexity level 2c ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n",
      "--- Complexity level 3 ---\n",
      "elevation zonal statistics\n",
      "slope zonal statistics\n",
      "aspect zonal statistics\n",
      "landcover zonal statistics\n",
      "soil zonal statistics\n",
      "landcover and soil types \n",
      "convert landcover int to string\n",
      "convert ROSETTA soil to STAS \n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "for level in level_list:\n",
    "\n",
    "    print('--- Complexity level %s ---' %(level))\n",
    "    \n",
    "    #  --- PART 1. define hru complexity level dependent files --- \n",
    "    hru_str      = 'hru_lev' + str(level)\n",
    "    hru_str_simp = hru_str + '_simplified'     \n",
    "    \n",
    "    hru_vector      = os.path.join(results_path, hru_str+'.shp')\n",
    "    hru_vector_simp = os.path.join(results_path, hru_str_simp+'.shp')    \n",
    "    \n",
    "    # --- PART 2. calculate zonal statistics ---\n",
    "    for invector in [hru_vector_simp]:\n",
    "        \n",
    "        # (1) define invector dependent files \n",
    "        invector_field       = hruNo_fieldname\n",
    "        invector_field_dtype = hruNo_field_dtype\n",
    "        \n",
    "        attrb_elev = os.path.join(results_path, invector.split('.shp')[0]+'_attrb_elevation.tif')        \n",
    "        attrb_slp  = os.path.join(results_path, invector.split('.shp')[0]+'_attrb_slope.tif')        \n",
    "        attrb_asp  = os.path.join(results_path, invector.split('.shp')[0]+'_attrb_aspect.tif')        \n",
    "        attrb_lc   = os.path.join(results_path, invector.split('.shp')[0]+'_attrb_landcover.tif')        \n",
    "        attrb_soil = os.path.join(results_path, invector.split('.shp')[0]+'_attrb_soil.tif')        \n",
    "        \n",
    "        # (2) elevation zonal statistics \n",
    "        print('elevation zonal statistics')\n",
    "        ga.zonal_statistic(basin_dem_raster, invector, invector_field, invector_field_dtype, \n",
    "                           refraster, 'mean', attrb_elev, output_column_prefix='elev')\n",
    "\n",
    "        # (3) slope zonal statistics \n",
    "        print('slope zonal statistics')\n",
    "        ga.zonal_statistic(basin_slope_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mean', attrb_slp, output_column_prefix='slope')\n",
    "\n",
    "        # (4) aspect zonal statistics \n",
    "        print('aspect zonal statistics')\n",
    "        ga.zonal_statistic(basin_aspect_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mean_aspect', attrb_asp, output_column_prefix='aspect')\n",
    "\n",
    "        # (5) landcover zonal statistics \n",
    "        print('landcover zonal statistics')\n",
    "        ga.zonal_statistic(basin_landcover_resample_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mode', attrb_lc, output_column_prefix='vegType')     #basin_canopy_class_raster    \n",
    "        \n",
    "        # (6) soil zonal statistics \n",
    "        print('soil zonal statistics')\n",
    "        ga.zonal_statistic(basin_soiltype_raster, invector, invector_field, invector_field_dtype, refraster, \n",
    "                           'mode', attrb_soil, output_column_prefix='soilType')        \n",
    "        \n",
    "        ## -------- post-process attributes for SUMMA ---------\n",
    "        # (7) landcover and soil types \n",
    "        print('landcover and soil types ')\n",
    "        # convert landcover int to [1,17] range \n",
    "        # change soilType from float to int (because source soilType is float)\n",
    "        in_gpd             = gpd.read_file(invector)\n",
    "        in_gpd['vegType']  = in_gpd['vegType']\n",
    "        in_gpd['soilType'] = in_gpd['soilType'].astype('int')\n",
    "        in_gpd.to_file(invector)\n",
    "        \n",
    "        # (8) convert landcover int to string for easy understanding\n",
    "        print('convert landcover int to string')\n",
    "        lcClass_list = [ 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 0, 255]\n",
    "        lcValue_list = ['Evergreen needleleaf forests', 'Evergreen broadleaf forests', 'Deciduous needleleaf forests',\n",
    "                        'Deciduous broadleaf forests', 'Mixed forests', 'Closed shrublands', 'Open shrublands', \n",
    "                        'Woody savannas', 'Savannas', 'Grasslands', 'Permanent wetlands', 'Croplands', \n",
    "                        'Urban and built-up lands', 'Cropland/natural vegetation mosaics', 'Snow and ice', \n",
    "                        'Barren', 'Water bodies', 'None']\n",
    "        in_gpd              = gpd.read_file(invector)\n",
    "        in_gpd['landcover'] = \"\"\n",
    "        for irow, row in in_gpd.iterrows():\n",
    "            lcClass = in_gpd.loc[irow,'vegType'] \n",
    "            lcValue = lcValue_list[lcClass_list.index(lcClass)]\n",
    "            in_gpd.at[irow,'landcover'] = lcValue\n",
    "        in_gpd['landcover'] = in_gpd['landcover'].astype('str')\n",
    "        in_gpd.to_file(invector)\n",
    "\n",
    "        # (9) convert ROSETTA soil to STAS and add string for easy understanding\n",
    "        print('convert ROSETTA soil to STAS ')\n",
    "        soilClass_list = [ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "        soilValue_list = ['OTHER(land-ice)', 'CLAY', 'CLAY LOAM', 'LOAM', 'LOAMY SAND', 'SAND', 'SANDY CLAY', \n",
    "                          'SANDY CLAY LOAM', 'SANDY LOAM', 'SILT','SILTY CLAY', 'SILTY CLAY LOAM', 'SILT LOAM']\n",
    "        soilClass_list_STAS = [16, 12, 9, 6, 2, 1, 10, 7, 3, 5, 11, 8, 4]\n",
    "        \n",
    "        in_gpd = gpd.read_file(invector)\n",
    "        # in_gpd['soilROSE'] = in_gpd['soilType'] #soilROSETTA\n",
    "        # in_gpd['soilSTAS']    = \"\"\n",
    "        in_gpd['soil']        = \"\"\n",
    "        for irow, row in in_gpd.iterrows():\n",
    "            \n",
    "            soilClass = in_gpd.loc[irow,'soilType'] \n",
    "            if soilClass==0:\n",
    "                lcClass = in_gpd.loc[irow,'vegType'] \n",
    "                # print('hruNo = %d, soilType_ROSETTA = 0, and vegType = %s.'%(in_gpd.loc[irow,'hruNo'],lcClass))\n",
    "            \n",
    "            soilValue      = soilValue_list[soilClass_list.index(soilClass)]\n",
    "            soilClass_STAS = soilClass_list_STAS[soilClass_list.index(soilClass)]\n",
    "            \n",
    "            in_gpd.at[irow,'soil']     = soilValue\n",
    "            # in_gpd.at[irow,'soilSTAS'] = soilClass_STAS\n",
    "            \n",
    "        # in_gpd['soil']     = in_gpd['soil'].astype('str')\n",
    "        # # in_gpd['soilSTAS'] = in_gpd['soilSTAS'].astype('int')\n",
    "        # # in_gpd['soilType'] = in_gpd['soilSTAS']\n",
    "        # # in_gpd = in_gpd.drop(columns=['soilSTAS'])\n",
    "        # # in_gpd = in_gpd.drop(columns=['soilType'])\n",
    "        # in_gpd.to_file(invector)\n",
    "\n",
    "        # # (10) convert slope to tan_slope \n",
    "        # in_gpd              = gpd.read_file(invector)\n",
    "        # in_gpd['tan_slope'] = np.tan(np.radians(in_gpd['slope']))\n",
    "        # in_gpd.to_file(invector)\n",
    "\n",
    "        # # (11) calculate contourLength (meter)\n",
    "        # # assuming the hru area is a circle and taking the radius as contourLength.\n",
    "        # in_gpd                  = gpd.read_file(invector)\n",
    "        # in_gpd['ctrLength'] = np.power(in_gpd['areaSqm']/np.pi,0.5)\n",
    "        # in_gpd.to_file(invector)\n",
    "\n",
    "        # # (12) calculate centroid lat/lon (degree)\n",
    "        # print('calculate centroid lat/lon')\n",
    "        # def getXY(pt):\n",
    "        #     return (pt.x, pt.y)\n",
    "        # in_gpd         = gpd.read_file(invector)\n",
    "        # in_gpd_prj     = in_gpd.to_crs(epsg=4326) # WGS84\n",
    "        # centroidseries = in_gpd_prj['geometry'].centroid\n",
    "        # in_gpd['longitude'],in_gpd['latitude'] = [list(t) for t in zip(*map(getXY, centroidseries))]\n",
    "        # in_gpd.to_file(invector)\n",
    "\n",
    "    # --- PART 3. save HRU with attributes into gpkg ---\n",
    "    invector_gpkg = invector.split('.shp')[0]+'.gpkg'\n",
    "    in_gpd        = gpd.read_file(invector)\n",
    "    in_gpd.to_file(invector_gpkg, driver=\"GPKG\")\n",
    "    print('Complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add nexus- field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "level_list = ['0','1a','1b','1c','2a','2b','2c','3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 0 ---\n",
      "--- Complexity level 1a ---\n",
      "--- Complexity level 1b ---\n",
      "--- Complexity level 1c ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hongliliu/venvs/discretize/lib/python3.9/site-packages/pyogrio/raw.py:196: RuntimeWarning: GPKG: bad application_id=0x00000000 on '/Users/hongliliu/Documents/tmp/utah/results_hru/hru_lev1c_simplified.gpkg'\n",
      "  return ogr_read(\n",
      "/Users/hongliliu/venvs/discretize/lib/python3.9/site-packages/pyogrio/raw.py:709: RuntimeWarning: GPKG: bad application_id=0x00000000 on '/Users/hongliliu/Documents/tmp/utah/results_hru/hru_lev1c_simplified.gpkg'\n",
      "  ogr_write(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Complexity level 2a ---\n",
      "--- Complexity level 2b ---\n",
      "--- Complexity level 2c ---\n",
      "--- Complexity level 3 ---\n"
     ]
    }
   ],
   "source": [
    "# common paths\n",
    "control_file    = '../control_Utah.txt'\n",
    "\n",
    "# temporary folder for test only\n",
    "results_path    = os.path.join(basin_data_path, 'results_hru/')\n",
    "basin_gru_shp         = ut.read_from_control(control_file, 'basin_gru_shp')\n",
    "\n",
    "for level in level_list:\n",
    "\n",
    "    print('--- Complexity level %s ---' %(level))\n",
    "    \n",
    "    #  --- PART 1. define output files of discretization--- \n",
    "    hru_str         = 'hru_lev' + str(level)\n",
    "    hru_str_simp    = hru_str + '_simplified'     \n",
    "    \n",
    "    hru_vector      = os.path.join(results_path, hru_str+'.shp')\n",
    "    hru_vector_simp = os.path.join(results_path, hru_str_simp+'.gpkg')    \n",
    "\n",
    "    #  --- PART 2. use gruId to obtain the corresponding divide_id and toid.\n",
    "    # Load the shapefiles\n",
    "    hru_simp_shp = gpd.read_file(hru_vector_simp)\n",
    "    basin_gru_shp_df = gpd.read_file(basin_gru_shp)\n",
    "    \n",
    "    # remove the two new columns if existing beforehand\n",
    "    if 'divide_id' in hru_simp_shp.columns:\n",
    "        hru_simp_shp = hru_simp_shp.drop(columns=['divide_id'])\n",
    "    if 'toid' in hru_simp_shp.columns:\n",
    "        hru_simp_shp = hru_simp_shp.drop(columns=['toid'])\n",
    "        \n",
    "    # Create the 'divide_id' column in hru_simp_shp\n",
    "    hru_simp_shp['divide_id'] = 'cat-' + hru_simp_shp['gruId'].astype(str)\n",
    "\n",
    "    # Merge with the basin_gru_shp_df to get 'toid'\n",
    "    merged_df = hru_simp_shp.merge(basin_gru_shp_df[['divide_id', 'toid']], on='divide_id', how='left')\n",
    "\n",
    "    # Update the hru_simp_shp with the new columns\n",
    "    hru_simp_shp['toid'] = merged_df['toid']\n",
    "\n",
    "    # Update 'divide_id' column with hruId\n",
    "    hru_simp_shp['divide_id'] = hru_simp_shp['hruId']\n",
    "    \n",
    "    # Save the updated shapefile\n",
    "    hru_simp_shp.to_file(hru_vector_simp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discretize",
   "language": "python",
   "name": "discretize"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
